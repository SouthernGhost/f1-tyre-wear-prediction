{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score,train_test_split\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_labels = ['Driver', 'DriverNumber', 'LapNumber', 'Compound',\n",
    "                     'TyreLife', 'Year', 'GrandPrix', 'AirTemp', 'Humidity', 'Pressure',\n",
    "                     'TrackTemp', 'WindDirection', 'WindSpeed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Driver', 'DriverNumber', 'LapTime', 'LapNumber', 'Compound',\n",
       "       'TyreLife', 'Year', 'GrandPrix', 'AirTemp', 'Humidity', 'Pressure',\n",
       "       'TrackTemp', 'WindDirection', 'WindSpeed'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('lap_data\\\\[2023, 2024].csv')\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Driver  \t\tobject\n",
      "DriverNumber  \t\tint64\n",
      "LapTime  \t\tfloat64\n",
      "LapNumber  \t\tfloat64\n",
      "Compound  \t\tobject\n",
      "TyreLife  \t\tfloat64\n",
      "Year  \t\tint64\n",
      "GrandPrix  \t\tobject\n",
      "AirTemp  \t\tfloat64\n",
      "Humidity  \t\tfloat64\n",
      "Pressure  \t\tfloat64\n",
      "TrackTemp  \t\tfloat64\n",
      "WindDirection  \t\tint64\n",
      "WindSpeed  \t\tfloat64\n"
     ]
    }
   ],
   "source": [
    "for cols in df.columns:\n",
    "    print(cols+\"  \\t\\t\"+str(df[cols].dtype))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Driver  \t\t0\n",
      "DriverNumber  \t\t0\n",
      "LapTime  \t\t583\n",
      "LapNumber  \t\t0\n",
      "Compound  \t\t0\n",
      "TyreLife  \t\t0\n",
      "Year  \t\t0\n",
      "GrandPrix  \t\t0\n",
      "AirTemp  \t\t0\n",
      "Humidity  \t\t0\n",
      "Pressure  \t\t0\n",
      "TrackTemp  \t\t0\n",
      "WindDirection  \t\t0\n",
      "WindSpeed  \t\t0\n"
     ]
    }
   ],
   "source": [
    "for cols in df.columns:\n",
    "    print(cols+'  \\t\\t'+str(df[cols].isna().sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(axis=0,how='any',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Driver 0\n",
      "DriverNumber 0\n",
      "LapTime 0\n",
      "LapNumber 0\n",
      "Compound 0\n",
      "TyreLife 0\n",
      "Year 0\n",
      "GrandPrix 0\n",
      "AirTemp 0\n",
      "Humidity 0\n",
      "Pressure 0\n",
      "TrackTemp 0\n",
      "WindDirection 0\n",
      "WindSpeed 0\n"
     ]
    }
   ],
   "source": [
    "for cols in df.columns:\n",
    "    print(cols+' '+str(df[cols].isna().sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler,OrdinalEncoder\n",
    "from tensorflow import keras\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "scale_cols = ['LapNumber', 'TyreLife', 'AirTemp', 'TrackTemp', 'WindSpeed']\n",
    "categorical_cols = ['GrandPrix', 'Compound', 'DriverNumber', 'WindDirection']\n",
    "encoder = OrdinalEncoder()\n",
    "scaler = StandardScaler()\n",
    "df['GrandPrix']=encoder.fit_transform(np.array(df['GrandPrix']).reshape(-1,1))\n",
    "df['Compound']=encoder.fit_transform(np.array(df['Compound']).reshape(-1,1))\n",
    "df['DriverNumber']=encoder.fit_transform(np.array(df['DriverNumber']).reshape(-1,1))\n",
    "df['WindDirection']=encoder.fit_transform(np.array(df['WindDirection']).reshape(-1,1))\n",
    "df[scale_cols]=scaler.fit_transform(df[scale_cols])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43913, 14)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Driver 0\n",
      "DriverNumber 0\n",
      "LapTime 0\n",
      "LapNumber 0\n",
      "Compound 0\n",
      "TyreLife 0\n",
      "Year 0\n",
      "GrandPrix 0\n",
      "AirTemp 0\n",
      "Humidity 0\n",
      "Pressure 0\n",
      "TrackTemp 0\n",
      "WindDirection 0\n",
      "WindSpeed 0\n"
     ]
    }
   ],
   "source": [
    "for cols in df.columns:\n",
    "    print(cols+' '+str(df[cols].isna().sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43913, 12)\n",
      "(43913, 1)\n"
     ]
    }
   ],
   "source": [
    "x=df.drop(labels=['LapTime','Driver'],axis=1).dropna(axis=0,how='any')\n",
    "y=df.drop(labels=drop_labels,axis=1).dropna(axis=0,how='any')\n",
    "x=x.to_numpy()\n",
    "y=y.to_numpy()\n",
    "\n",
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cross Validation:  [-2.23736025e-01  5.03289959e-02 -1.95991502e+00  2.63247189e-04\n",
      " -9.24672679e-02]\n",
      "\n",
      "Mean accuracy:  -0.4451052131734417\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "rgs = LinearRegression(positive=True,fit_intercept=True)\n",
    "score = cross_val_score(estimator=rgs,X=x,y=y)\n",
    "print('\\nCross Validation: ',score)\n",
    "print('\\nMean accuracy: ',np.mean(np.array(score)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ghost\\anaconda3\\envs\\py310\\lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\Ghost\\anaconda3\\envs\\py310\\lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\Ghost\\anaconda3\\envs\\py310\\lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\Ghost\\anaconda3\\envs\\py310\\lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\Ghost\\anaconda3\\envs\\py310\\lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cross Validation:  [-8.51216637e+01 -3.55060529e-01 -1.36885411e+00 -4.78475405e-04\n",
      " -3.53362247e+00]\n",
      "\n",
      "Mean accuracy:  -18.075935851411096\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rndm = RandomForestRegressor(n_estimators=10)\n",
    "score = cross_val_score(estimator=rndm,X=x,y=y)\n",
    "print('\\nCross Validation: ',score)\n",
    "print('\\nMean accuracy: ',np.mean(np.array(score)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ghost\\anaconda3\\envs\\py310\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 8.428418563141925\n",
      "R-squared: 0.996045322341599\n"
     ]
    }
   ],
   "source": [
    "# Importing necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import joblib\n",
    "\n",
    "# Step 1: Load your dataset\n",
    "# Assuming 'LapTime' is the target variable in your dataset\n",
    "# Replace 'data.csv' with your actual data file path\n",
    "df = pd.read_csv('lap_data\\\\[2023, 2024].csv')\n",
    "\n",
    "# Step 2: Data Preprocessing\n",
    "\n",
    "# 2a. Handle categorical features: OneHotEncoding for ['DriverNumber', 'Compound', 'GrandPrix', 'WindDirection']\n",
    "categorical_features = ['DriverNumber', 'Compound', 'GrandPrix', 'WindDirection']\n",
    "encoder = OneHotEncoder(sparse=False, drop='first')  # drop='first' to avoid multicollinearity\n",
    "\n",
    "encoded_data = encoder.fit_transform(df[categorical_features])\n",
    "encoded_df = pd.DataFrame(encoded_data, columns=encoder.get_feature_names_out(categorical_features))\n",
    "\n",
    "# 2b. Join the encoded features back to the original dataframe\n",
    "df = df.join(encoded_df)\n",
    "\n",
    "# 2c. Drop the original categorical columns\n",
    "df.drop(columns=categorical_features, inplace=True)\n",
    "\n",
    "# 2d. Handle missing data (optional): Impute or drop missing values\n",
    "#df.fillna(df.mean(), inplace=True)\n",
    "\n",
    "# 2e. Feature Scaling: Standardize numerical columns ['LapNumber', 'TyreLife', 'AirTemp', 'TrackTemp', 'WindSpeed']\n",
    "numerical_features = ['LapNumber', 'TyreLife', 'AirTemp', 'TrackTemp', 'WindSpeed']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "df[numerical_features] = scaler.fit_transform(df[numerical_features])\n",
    "\n",
    "# Step 3: Model Training\n",
    "df.dropna(axis=0,how='any',inplace=True)\n",
    "# 3a. Define features (X) and target (y)\n",
    "X = df.drop(columns=['LapTime','Driver'])  # Assuming 'LapTime' is the target variable\n",
    "y = df['LapTime']\n",
    "\n",
    "# 3b. Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 4: Train a Random Forest Regressor\n",
    "rf_model = RandomForestRegressor(n_estimators=15,random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Step 5: Model Evaluation\n",
    "\n",
    "# 5a. Predict on the test set\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# 5b. Calculate evaluation metrics: MSE and R-squared\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "print(f'R-squared: {r2}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 6: Hyperparameter Tuning with GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [20, 30, 50],\n",
    "    'max_depth': [10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=rf_model, param_grid=param_grid, cv=5, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Step 7: Retrieve the best model\n",
    "best_rf = grid_search.best_estimator_\n",
    "\n",
    "# Step 8: Evaluate the tuned model\n",
    "y_pred_best = best_rf.predict(X_test)\n",
    "mse_best = mean_squared_error(y_test, y_pred_best)\n",
    "r2_best = r2_score(y_test, y_pred_best)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "\n",
    "print(f'Tuned Model Mean Squared Error: {mse_best}')\n",
    "print(f'Tuned Model R-squared: {r2_best}')\n",
    "\n",
    "# Step 9: Feature Importance (Optional)\n",
    "importances = best_rf.feature_importances_\n",
    "features = X_train.columns\n",
    "feature_importance = pd.DataFrame({'Feature': features, 'Importance': importances})\n",
    "print(feature_importance.sort_values(by='Importance', ascending=False))\n",
    "\n",
    "# Step 10: Save the trained model\n",
    "joblib.dump(best_rf, 'f1_lap_time_predictor.pkl')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
